#!/usr/bin/env python3
"""
SU:DA - ìˆ˜í™” ì¸ì‹ ì‹œìŠ¤í…œ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
ê³µí†µìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” í•¨ìˆ˜ë“¤ê³¼ ì„¤ì •ì„ ê´€ë¦¬
"""

import os
import json
import logging
import torch
import numpy as np
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Any
import cv2
from datetime import datetime

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì„¤ì •
PROJECT_ROOT = Path(__file__).parent.parent
DATA_RAW_PATH = PROJECT_ROOT / "data" / "raw"
DATA_PROCESSED_PATH = PROJECT_ROOT / "data" / "processed"
OUTPUTS_PATH = PROJECT_ROOT / "outputs"
CHECKPOINTS_PATH = OUTPUTS_PATH / "checkpoints"
LOGS_PATH = OUTPUTS_PATH / "logs"

# ë°ì´í„° ì„¤ì •
WORD_START = 1501
WORD_END = 3000
TOTAL_WORDS = WORD_END - WORD_START + 1  # 1500ê°œ
SPEAKER_ID = "REAL01"
DIRECTION = "F"

# ëª¨ë¸ ì„¤ì •
KEYPOINT_DIM = 543  # MediaPipe: 33(pose) + 21*2(hands) + 468(face) = 543 landmarks
HIDDEN_DIM = 256
NUM_LAYERS = 2
DROPOUT = 0.3
LEARNING_RATE = 0.001
BATCH_SIZE = 32
NUM_EPOCHS = 100

# í‚¤í¬ì¸íŠ¸ êµ¬ì¡° ì •ì˜
POSE_LANDMARKS = 33
HAND_LANDMARKS = 21
FACE_LANDMARKS = 468
TOTAL_LANDMARKS = POSE_LANDMARKS + HAND_LANDMARKS * 2 + FACE_LANDMARKS

def setup_directories():
    """í•„ìš”í•œ ë””ë ‰í† ë¦¬ë“¤ì„ ìƒì„±"""
    directories = [
        DATA_PROCESSED_PATH / "sequences",
        DATA_PROCESSED_PATH / "splits", 
        DATA_PROCESSED_PATH / "vocab",
        CHECKPOINTS_PATH,
        LOGS_PATH,
        LOGS_PATH / "tensorboard"
    ]
    
    for directory in directories:
        directory.mkdir(parents=True, exist_ok=True)
    
    return directories

def setup_logger(name: str, log_file: Optional[str] = None, level=logging.INFO) -> logging.Logger:
    """ë¡œê±° ì„¤ì •"""
    logger = logging.getLogger(name)
    logger.setLevel(level)
    
    # ê¸°ì¡´ í•¸ë“¤ëŸ¬ ì œê±° (ì¤‘ë³µ ë°©ì§€)
    if logger.handlers:
        logger.handlers.clear()
    
    # í¬ë§·í„° ì„¤ì •
    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    
    # ì½˜ì†” í•¸ë“¤ëŸ¬
    console_handler = logging.StreamHandler()
    console_handler.setFormatter(formatter)
    logger.addHandler(console_handler)
    
    # íŒŒì¼ í•¸ë“¤ëŸ¬ (ì„ íƒì )
    if log_file:
        LOGS_PATH.mkdir(parents=True, exist_ok=True)
        file_handler = logging.FileHandler(LOGS_PATH / log_file)
        file_handler.setFormatter(formatter)
        logger.addHandler(file_handler)
    
    return logger

def load_json(file_path: Path) -> Dict[str, Any]:
    """JSON íŒŒì¼ ë¡œë”©"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        raise FileNotFoundError(f"JSON íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
    except json.JSONDecodeError as e:
        raise ValueError(f"JSON íŒŒì‹± ì˜¤ë¥˜ ({file_path}): {e}")

def save_json(data: Dict[str, Any], file_path: Path):
    """JSON íŒŒì¼ ì €ì¥"""
    file_path.parent.mkdir(parents=True, exist_ok=True)
    with open(file_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

def get_video_fps(video_path: Path) -> float:
    """ë¹„ë””ì˜¤ íŒŒì¼ì˜ FPS ì¶”ì¶œ"""
    cap = cv2.VideoCapture(str(video_path))
    if not cap.isOpened():
        raise ValueError(f"ë¹„ë””ì˜¤ íŒŒì¼ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}")
    
    fps = cap.get(cv2.CAP_PROP_FPS)
    cap.release()
    
    if fps <= 0:
        fps = 30.0  # ê¸°ë³¸ê°’
        print(f"âš ï¸ FPSë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ì–´ ê¸°ë³¸ê°’ {fps} ì‚¬ìš©: {video_path}")
    
    return fps

def time_to_frame_index(time_seconds: float, fps: float) -> int:
    """ì‹œê°„(ì´ˆ)ì„ í”„ë ˆì„ ì¸ë±ìŠ¤ë¡œ ë³€í™˜"""
    return int(time_seconds * fps)

def extract_keypoints_from_json(keypoint_json: Dict[str, Any]) -> np.ndarray:
    """í‚¤í¬ì¸íŠ¸ JSONì—ì„œ ì¢Œí‘œ ë°°ì—´ ì¶”ì¶œ"""
    try:
        people = keypoint_json.get("people", {})
        if isinstance(people, list) and len(people) > 0:
            person = people[0]
        elif isinstance(people, dict):
            person = people
        else:
            # ë¹ˆ í‚¤í¬ì¸íŠ¸ ë°˜í™˜
            return np.zeros(TOTAL_LANDMARKS * 3)
        
        keypoints = []
        
        # Pose keypoints (33ê°œ)
        pose_2d = person.get("pose_keypoints_2d", [])
        if len(pose_2d) >= POSE_LANDMARKS * 3:
            keypoints.extend(pose_2d[:POSE_LANDMARKS * 3])
        else:
            keypoints.extend([0.0] * (POSE_LANDMARKS * 3))
        
        # Left hand keypoints (21ê°œ)
        hand_left_2d = person.get("hand_left_keypoints_2d", [])
        if len(hand_left_2d) >= HAND_LANDMARKS * 3:
            keypoints.extend(hand_left_2d[:HAND_LANDMARKS * 3])
        else:
            keypoints.extend([0.0] * (HAND_LANDMARKS * 3))
        
        # Right hand keypoints (21ê°œ)
        hand_right_2d = person.get("hand_right_keypoints_2d", [])
        if len(hand_right_2d) >= HAND_LANDMARKS * 3:
            keypoints.extend(hand_right_2d[:HAND_LANDMARKS * 3])
        else:
            keypoints.extend([0.0] * (HAND_LANDMARKS * 3))
        
        # Face keypoints (468ê°œ)
        face_2d = person.get("face_keypoints_2d", [])
        if len(face_2d) >= FACE_LANDMARKS * 3:
            keypoints.extend(face_2d[:FACE_LANDMARKS * 3])
        else:
            keypoints.extend([0.0] * (FACE_LANDMARKS * 3))
        
        return np.array(keypoints, dtype=np.float32)
        
    except Exception as e:
        print(f"âš ï¸ í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        return np.zeros(TOTAL_LANDMARKS * 3, dtype=np.float32)

def normalize_keypoints(keypoints: np.ndarray) -> np.ndarray:
    """í‚¤í¬ì¸íŠ¸ ì •ê·œí™” (x, yëŠ” 0-1ë¡œ, confidenceëŠ” ê·¸ëŒ€ë¡œ)"""
    if len(keypoints) == 0:
        return keypoints
    
    # 3ê°œì”© ë¬¶ì–´ì„œ ì²˜ë¦¬ (x, y, confidence)
    normalized = keypoints.copy()
    for i in range(0, len(keypoints), 3):
        if i + 2 < len(keypoints):
            # x, y ì¢Œí‘œë§Œ ì •ê·œí™” (0-1 ë²”ìœ„ë¡œ ê°€ì •)
            normalized[i] = np.clip(keypoints[i], 0, 1)      # x
            normalized[i+1] = np.clip(keypoints[i+1], 0, 1)  # y
            # confidenceëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€
            normalized[i+2] = np.clip(keypoints[i+2], 0, 1)  # conf
    
    return normalized

def pad_sequence(sequence: np.ndarray, max_length: int, pad_value: float = 0.0) -> np.ndarray:
    """ì‹œí€€ìŠ¤ë¥¼ ê³ ì • ê¸¸ì´ë¡œ íŒ¨ë”©"""
    seq_len = len(sequence)
    
    if seq_len >= max_length:
        # ê¸¸ì´ê°€ ê¸´ ê²½ìš° ì•ë¶€ë¶„ ìë¥´ê¸°
        return sequence[:max_length]
    else:
        # ê¸¸ì´ê°€ ì§§ì€ ê²½ìš° ë’¤ì— íŒ¨ë”© ì¶”ê°€
        pad_length = max_length - seq_len
        if len(sequence.shape) == 1:
            padding = np.full(pad_length, pad_value)
        else:
            padding = np.full((pad_length, sequence.shape[1]), pad_value)
        return np.concatenate([sequence, padding], axis=0)

def save_checkpoint(model, optimizer, epoch: int, loss: float, accuracy: float, 
                   checkpoint_path: Path, is_best: bool = False):
    """ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ì €ì¥"""
    checkpoint = {
        'epoch': epoch,
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'loss': loss,
        'accuracy': accuracy,
        'timestamp': datetime.now().isoformat()
    }
    
    # ê¸°ë³¸ ì²´í¬í¬ì¸íŠ¸ ì €ì¥
    torch.save(checkpoint, checkpoint_path)
    
    # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥
    if is_best:
        best_path = checkpoint_path.parent / "best.pt"
        torch.save(checkpoint, best_path)
        print(f"âœ… ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥: {best_path}")

def load_checkpoint(checkpoint_path: Path, model, optimizer=None) -> Dict[str, Any]:
    """ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ë¡œë”©"""
    if not checkpoint_path.exists():
        raise FileNotFoundError(f"ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {checkpoint_path}")
    
    checkpoint = torch.load(checkpoint_path, map_location='cpu')
    
    # ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë”©
    model.load_state_dict(checkpoint['model_state_dict'])
    
    # ì˜µí‹°ë§ˆì´ì € ê°€ì¤‘ì¹˜ ë¡œë”© (ì„ íƒì )
    if optimizer is not None and 'optimizer_state_dict' in checkpoint:
        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
    
    print(f"âœ… ì²´í¬í¬ì¸íŠ¸ ë¡œë”© ì™„ë£Œ: epoch {checkpoint['epoch']}, "
          f"loss {checkpoint['loss']:.4f}, accuracy {checkpoint['accuracy']:.4f}")
    
    return checkpoint

def get_device() -> torch.device:
    """ì‚¬ìš© ê°€ëŠ¥í•œ ë””ë°”ì´ìŠ¤ ë°˜í™˜"""
    if torch.cuda.is_available():
        device = torch.device("cuda")
        print(f"âœ… CUDA ì‚¬ìš©: {torch.cuda.get_device_name()}")
    elif torch.backends.mps.is_available():
        device = torch.device("mps")
        print("âœ… Apple MPS ì‚¬ìš©")
    else:
        device = torch.device("cpu")
        print("âœ… CPU ì‚¬ìš©")
    
    return device

def count_parameters(model) -> int:
    """ëª¨ë¸ íŒŒë¼ë¯¸í„° ê°œìˆ˜ ê³„ì‚°"""
    return sum(p.numel() for p in model.parameters() if p.requires_grad)

def get_word_id_from_filename(filename: str) -> int:
    """íŒŒì¼ëª…ì—ì„œ ë‹¨ì–´ ID ì¶”ì¶œ (ì˜ˆ: NIA_SL_WORD1501_REAL01_F -> 1501)"""
    try:
        parts = filename.split('_')
        for part in parts:
            if part.startswith('WORD'):
                return int(part[4:])  # 'WORD' ì œê±° í›„ ìˆ«ì ì¶”ì¶œ
        raise ValueError(f"íŒŒì¼ëª…ì—ì„œ ë‹¨ì–´ IDë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {filename}")
    except (ValueError, IndexError):
        raise ValueError(f"ì˜ëª»ëœ íŒŒì¼ëª… í˜•ì‹: {filename}")

def is_valid_word_id(word_id: int) -> bool:
    """ìœ íš¨í•œ ë‹¨ì–´ ID ë²”ìœ„ ì²´í¬"""
    return WORD_START <= word_id <= WORD_END

def create_word_range() -> List[int]:
    """í•™ìŠµì— ì‚¬ìš©í•  ë‹¨ì–´ ID ë²”ìœ„ ìƒì„±"""
    return list(range(WORD_START, WORD_END + 1))

def format_time(seconds: float) -> str:
    """ì´ˆë¥¼ ì‹œ:ë¶„:ì´ˆ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    
    if hours > 0:
        return f"{hours:02d}:{minutes:02d}:{secs:02d}"
    else:
        return f"{minutes:02d}:{secs:02d}"

def print_system_info():
    """ì‹œìŠ¤í…œ ì •ë³´ ì¶œë ¥"""
    print("=" * 50)
    print("ğŸš€ SU:DA - ìˆ˜í™” ì¸ì‹ ì‹œìŠ¤í…œ")
    print("=" * 50)
    print(f"ğŸ“‚ í”„ë¡œì íŠ¸ ë£¨íŠ¸: {PROJECT_ROOT}")
    print(f"ğŸ“Š ë°ì´í„° ë²”ìœ„: WORD{WORD_START}~{WORD_END} ({TOTAL_WORDS}ê°œ)")
    print(f"ğŸ‘¤ í™”ì: {SPEAKER_ID}")
    print(f"ğŸ“¹ ë°©í–¥: {DIRECTION} (ì •ë©´)")
    print(f"ğŸ¯ í‚¤í¬ì¸íŠ¸ ì°¨ì›: {TOTAL_LANDMARKS * 3}")
    print(f"ğŸ’¾ ë””ë°”ì´ìŠ¤: {get_device()}")
    print("=" * 50)

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ìš© ì½”ë“œ
    print_system_info()
    setup_directories()
    logger = setup_logger("utils_test", "test.log")
    logger.info("ìœ í‹¸ë¦¬í‹° ëª¨ë“ˆ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")